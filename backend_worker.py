# -*- coding: utf-8 -*-
import time
import random
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime, timedelta
import database as db
import ticket_core 

# ================= é…ç½®åŒº =================
BATCH_INTERVAL = 15  # å¿ƒè·³é—´éš”ç¼©çŸ­ä¸º 15ç§’ (ç”¨äºå¿«é€Ÿå‘ç°æ–°ä»»åŠ¡)
TASK_POLL_INTERVAL = 60 * 10  # å•ä¸ªä»»åŠ¡è½®è¯¢é—´éš” (10åˆ†é’Ÿ)
MAX_WORKERS = 3

def log(msg):
    print(f"[{datetime.now().strftime('%H:%M:%S')}] {msg}", flush=True)

def process_route_group(route_key, task_list):
    """Worker è°ƒç”¨çš„å¤„ç†å‡½æ•°"""
    f_st, t_st, date, m_st = route_key
    
    # éšæœºå»¶è¿Ÿé˜²æ­¢å¹¶å‘ç¬é—´æ’å¢™
    time.sleep(random.uniform(1.0, 5.0))
    
    # æ‰§è¡ŒæŸ¥è¯¢
    if m_st:
        success, count = ticket_core.query_transfer_and_notify(f_st, m_st, t_st, date, task_list)
    else:
        success, count = ticket_core.query_and_notify(f_st, t_st, date, task_list)
    
    # æ— è®ºæˆåŠŸä¸å¦ï¼Œåªè¦å°è¯•è¿‡æŸ¥è¯¢ï¼Œå°±æ›´æ–°æ£€æŸ¥æ—¶é—´
    # è¿™æ ·å¯ä»¥é˜²æ­¢ä»»åŠ¡è¢«æ— é™é‡è¯•ï¼Œç¬¦åˆ TASK_POLL_INTERVAL é™åˆ¶
    if success: # å¦‚æœå› é™æµå¤±è´¥(success=False)ï¼Œåˆ™ä¸æ›´æ–°æ—¶é—´ï¼Œä»¥ä¾¿ä¸‹è½®é‡è¯•(å—é™æµé”æ§åˆ¶)
        for task in task_list:
            db.update_check_time(task[0])
        log(f"âœ… å·²æ›´æ–° {len(task_list)} ä¸ªä»»åŠ¡çš„æ£€æŸ¥æ—¶é—´")

    if not success:
        log(f"âš ï¸ çº¿è·¯ {f_st}->{t_st} å› é™æµæœªæ‰§è¡Œ")

def worker_loop():
    log("ğŸš€ åå°ç›‘æ§æœåŠ¡å·²å¯åŠ¨ (æ™ºèƒ½è½®è¯¢ç‰ˆ)...")
    db.init_db()
    
    while True:
        try:
            all_tasks = db.get_active_tasks()
        except Exception as e:
            log(f"âŒ DBé”™è¯¯: {e}")
            time.sleep(5)
            continue
        
        if not all_tasks:
            # å³ä½¿æ²¡ä»»åŠ¡ä¹Ÿåªç¡çŸ­ä¸€ç‚¹ï¼Œé˜²æ­¢åˆšåŠ ä»»åŠ¡è¦ç­‰å¾ˆä¹…
            time.sleep(10)
            continue
        
        # 1. ç­›é€‰éœ€è¦æ‰§è¡Œçš„ä»»åŠ¡
        tasks_to_process = []
        current_time = datetime.now()
        
        for task in all_tasks:
            t_id = task[0]
            # è§£æ last_check_time (å‡è®¾ç¬¬11ä¸ªå­—æ®µæ˜¯ created, 12æ˜¯last_check... éœ€å…¼å®¹)
            # æœ€å¥½ç›´æ¥æ ¹æ®ç»“æ„å–ã€‚
            # ç»“æ„: id(0), user(1), f(2), t(3), date(4), tt(5), st(6), email(7), status(8), 
            #       created(9), last_check(10), last_notify(11), middle(12)
            
            last_check = task[10]
            last_notify = task[11]

            # --- æ£€æŸ¥1: æ˜¯å¦æœ‰ç¥¨åˆšé€šçŸ¥è¿‡ (3å°æ—¶å†·å´) ---
            if last_notify:
                if isinstance(last_notify, str):
                    try: last_notify = datetime.strptime(last_notify, "%Y-%m-%d %H:%M:%S")
                    except: pass
                if isinstance(last_notify, datetime):
                    if current_time - last_notify < timedelta(hours=3):
                        # å†·å´ä¸­ï¼Œç›´æ¥è·³è¿‡
                        continue

            # --- æ£€æŸ¥2: æ˜¯å¦åˆšæŸ¥è¿‡ (10åˆ†é’Ÿè½®è¯¢é—´éš”) ---
            # å¦‚æœ last_check ä¸º Noneï¼Œè¯´æ˜æ˜¯æ–°ä»»åŠ¡ï¼Œç«‹å³æ‰§è¡Œ
            should_run = True
            if last_check:
                if isinstance(last_check, str):
                    try: last_check = datetime.strptime(last_check, "%Y-%m-%d %H:%M:%S")
                    except: pass
                if isinstance(last_check, datetime):
                    if current_time - last_check < timedelta(seconds=TASK_POLL_INTERVAL):
                        should_run = False
            
            if should_run:
                tasks_to_process.append(task)
        
        if not tasks_to_process:
            # æ²¡æœ‰éœ€è¦è·‘çš„ä»»åŠ¡ï¼Œå®‰é™ä¼‘çœ 
            # log(f"ğŸ’¤ æš‚æ— å¾…åŠä»»åŠ¡ï¼Œå¾…æœºä¸­...") 
            time.sleep(BATCH_INTERVAL)
            continue

        log(f"âš¡ å‘ç° {len(tasks_to_process)} ä¸ªå¾…æ‰§è¡Œä»»åŠ¡...")

        # 2. åˆ†ç»„
        grouped_tasks = {}
        for task in tasks_to_process:
            # task[12] æ˜¯ middle_station
            m_st = task[12] if len(task) > 12 else None
            key = (task[2], task[3], task[4], m_st) 
            if key not in grouped_tasks: grouped_tasks[key] = []
            grouped_tasks[key].append(task)

        # 3. æ‰§è¡Œ
        route_keys = list(grouped_tasks.keys())
        for i, r_key in enumerate(route_keys):
            process_route_group(r_key, grouped_tasks[r_key])
            
            # ä»»åŠ¡é—´ç¨å¾®é—´éš”ï¼Œé˜²æ­¢ç¬é—´å¹¶å‘
            if i < len(route_keys) - 1:
                time.sleep(random.uniform(5, 10))

        log(f"âœ… æœ¬è½®æ‰§è¡Œå®Œæ¯•ï¼Œä¼‘çœ  {BATCH_INTERVAL} ç§’...\n")
        time.sleep(BATCH_INTERVAL)

if __name__ == "__main__":
    worker_loop()